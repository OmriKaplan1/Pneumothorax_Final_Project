# -*- coding: utf-8 -*-
"""Segmentation_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w2ix0qtOD3BmTxQuwiCERBB90oeWfYc8
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

# Commented out IPython magic to ensure Python compatibility.
import os
import cv2
import sys
import random
import warnings
import numpy as np
import pandas as pd
from time import time
import matplotlib.pyplot as plt
from tqdm import tqdm
from itertools import chain
from skimage.io import imread, imshow, imread_collection, concatenate_images
from skimage.transform import resize
from skimage.morphology import label

import tensorflow as tf
from tensorflow.keras.layers import Input, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, Concatenate, Activation, Add, multiply, add, concatenate, LeakyReLU, ZeroPadding2D, UpSampling2D, BatchNormalization
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras import backend as K

from sklearn.metrics import classification_report, confusion_matrix
# %matplotlib inline

IMG_HEIGHT = 256
IMG_WIDTH = 256
IMG_CHANNEL = 3
IMG_PATH = '/content/drive/My Drive/Project_Gmar_blat/png_images'
MASK_PATH = '/content/drive/My Drive/Project_Gmar_blat/png_masks'

warnings.filterwarnings('ignore', category=UserWarning, module='skimage')
seed = 42
random.seed = seed
np.random.seed = seed

train_df = pd.read_csv('/content/drive/My Drive/Project_Gmar_blat/stage_1_train_images.csv')
test_df = pd.read_csv('/content/drive/My Drive/Project_Gmar_blat/stage_1_test_images.csv')
train_df.head()
train_df_pneumo = train_df[train_df['has_pneumo'] == 1]

print("Getting and Resizing Train Images, Train Mask, and Adding Label ...\n\n")

# Create X_train, Y_train, and Label
X_train_seg = np.zeros((len(train_df_pneumo), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype=np.uint8)
Y_train_seg = np.zeros((len(train_df_pneumo), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)
Label_seg = np.zeros(len(train_df_pneumo), dtype=np.uint8)

img_data = list(train_df_pneumo.T.to_dict().values())

for i, data_row in tqdm(enumerate(img_data), total=len(img_data)):

    patientImage = data_row['new_filename']
    imageLabel  = data_row['has_pneumo']

    imagePath = os.path.join(IMG_PATH, patientImage)
    lungImage = imread(imagePath)
    lungImage = np.expand_dims(resize(lungImage, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)

    X_train_seg[i] = lungImage

    Label_seg[i] = imageLabel

    maskPath = os.path.join(MASK_PATH, patientImage)
    maskImage = imread(maskPath)
    maskImage = np.expand_dims(resize(maskImage, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)

    Y_train_seg[i] = maskImage

print('\n\nProcess ... C O M P L E T E')

# Illustrate the train images and masks
plt.figure(figsize=(20, 16))
x, y = 12, 4
for i in range(y):
    for j in range(x):
        plt.subplot(y*2, x, i*2*x+j+1)
        pos = i*120 + j*10
        plt.imshow(X_train_seg[pos], cmap=plt.cm.bone)
        plt.title('Image #{}'.format(pos))
        plt.axis('off')
        plt.subplot(y*2, x, (i*2+1)*x+j+1)

        plt.imshow(np.squeeze(Y_train_seg[pos]), cmap='gray_r')
        plt.title('Mask #{}\nLabel: {}'.format(pos, Label_seg[pos]))
        plt.axis('off')

plt.tight_layout()
plt.show()

#the is the the code to build the architecture for the segmentation model of images in the size of 256 * 256
import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras.optimizers import Adam

def conv_block(x, filters):
    x = layers.Conv2D(filters, 3, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.Conv2D(filters, 3, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    return x

def build_resnet_unet(input_shape=(256, 256, 3), num_classes=1):
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)

    # Encoder layers
    c1 = base_model.get_layer('conv1_relu').output        # 128x128
    c2 = base_model.get_layer('conv2_block3_out').output  # 64x64
    c3 = base_model.get_layer('conv3_block4_out').output  # 32x32
    c4 = base_model.get_layer('conv4_block6_out').output  # 16x16
    c5 = base_model.get_layer('conv5_block3_out').output  # 8x8

    # Decoder
    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = layers.concatenate([u6, c4])
    u6 = conv_block(u6, 512)

    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(u6)
    u7 = layers.concatenate([u7, c3])
    u7 = conv_block(u7, 256)

    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(u7)
    u8 = layers.concatenate([u8, c2])
    u8 = conv_block(u8, 128)

    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(u8)
    u9 = layers.concatenate([u9, c1])
    u9 = conv_block(u9, 64)

    u10 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(u9)
    u10 = conv_block(u10, 32)

    outputs = layers.Conv2D(num_classes, (1, 1), activation='sigmoid')(u10)

    model = Model(inputs=base_model.input, outputs=outputs)
    return model

from tensorflow.keras.losses import BinaryFocalCrossentropy
focal = BinaryFocalCrossentropy(gamma=2.0, from_logits=False)


def dice_loss(y_true, y_pred, smooth=1):
    y_true_f = tf.keras.backend.flatten(tf.cast(y_true, tf.float32))
    y_pred_f = tf.keras.backend.flatten(tf.cast(y_pred, tf.float32))
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return 1 - (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)

def iou_score(y_true, y_pred, smooth=1):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)
    intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])
    union = tf.reduce_sum(y_true + y_pred, axis=[1,2,3]) - intersection
    iou = (intersection + smooth) / (union + smooth)
    return tf.reduce_mean(iou)

def combined_loss(y_true, y_pred):
    return dice_loss(y_true, y_pred) + focal(y_true, y_pred)

model = build_resnet_unet(input_shape=(256, 256, 3), num_classes=1)
model.compile(optimizer=Adam(1e-3), loss=combined_loss, metrics=[iou_score])

from sklearn.model_selection import train_test_split
ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)
X_train, X_val, Y_train, Y_val = train_test_split(
    X_train_seg, Y_train_seg,
    test_size=0.1,          # 10% for validation
    random_state=42,        # for reproducibility
    shuffle=True
)
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Define callbacks
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=8,
    restore_best_weights=True,
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3,
    verbose=1,
    min_lr=1e-6
)

history = model.fit(
    X_train, Y_train,
    validation_data=(X_val, Y_val),
    epochs=45,
    batch_size=16,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),
        tf.keras.callbacks.ReduceLROnPlateau(patience=3)
    ]
)

# A plot of the IoU of the model during training. IoU stands for the areas that are mutual to the mask and the semgntation output.
import matplotlib.pyplot as plt

plt.plot(history.history['iou_score'], label='Train IoU')
plt.plot(history.history['val_iou_score'], label='Val IoU')
plt.title('IoU over Epochs')
plt.xlabel('Epoch')
plt.ylabel('IoU Score')
plt.legend()
plt.grid(True)
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

##SAVING THE MODEL
model.save("segmentation_model.keras")

from google.colab import files
files.download("segmentation_model.keras")

"""# LOADING AND TESTING SECTION

"""

from tensorflow.keras.models import load_model

# Re-import your custom objects
from tensorflow.keras.losses import BinaryFocalCrossentropy

# Define your custom loss and metric again
def dice_loss(y_true, y_pred, smooth=1):
    y_true_f = tf.keras.backend.flatten(tf.cast(y_true, tf.float32))
    y_pred_f = tf.keras.backend.flatten(tf.cast(y_pred, tf.float32))
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return 1 - (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)

def iou_score(y_true, y_pred, smooth=1):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)
    intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])
    union = tf.reduce_sum(y_true + y_pred, axis=[1,2,3]) - intersection
    iou = (intersection + smooth) / (union + smooth)
    return tf.reduce_mean(iou)

def combined_loss(y_true, y_pred):
    focal = BinaryFocalCrossentropy(gamma=2.0, from_logits=False)
    return dice_loss(y_true, y_pred) + focal(y_true, y_pred)

# Now load the model
model = load_model("/content/drive/My Drive/Project_Gmar_blat/segmentation_model.keras", custom_objects={
    'combined_loss': combined_loss,
    'iou_score': iou_score,
    'BinaryFocalCrossentropy': BinaryFocalCrossentropy,
    'dice_loss': dice_loss
})

print("Getting and Resizing Test Images, Test Mask, and Adding Label ...\n\n")
test_df_pneumo = test_df[test_df['has_pneumo'] == 1]
# Create X_train, Y_train, and Label
X_test_seg = np.zeros((len(test_df_pneumo), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype=np.uint8)
Y_test_seg = np.zeros((len(test_df_pneumo), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)
Label_seg = np.zeros(len(test_df_pneumo), dtype=np.uint8)

img_data = list(test_df_pneumo.T.to_dict().values())

for i, data_row in tqdm(enumerate(img_data), total=len(img_data)):

    patientImage = data_row['new_filename']
    imageLabel  = data_row['has_pneumo']

    imagePath = os.path.join(IMG_PATH, patientImage)
    lungImage = imread(imagePath)
    lungImage = np.expand_dims(resize(lungImage, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)

    X_test_seg[i] = lungImage

    Label_seg[i] = imageLabel

    maskPath = os.path.join(MASK_PATH, patientImage)
    maskImage = imread(maskPath)
    maskImage = np.expand_dims(resize(maskImage, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)

    Y_test_seg[i] = maskImage

print('\n\nProcess ... C O M P L E T E')

##test on 20 examples
import matplotlib.pyplot as plt
import numpy as np
import random

# Step 1: Predict on test set
pred_test = model.predict(X_test_seg, verbose=1)  # Shape: (N, 256, 256, 1)

# Step 2: Threshold predictions
pred_test_threshold = (pred_test > 0.4).astype(np.uint8)

# Step 3: Select 20 random indices
indices = random.sample(range(len(X_test_seg)), 20)

# Step 4: Plot each sample with filename
plt.figure(figsize=(15, 60))  # Tall figure for 20 rows

for i, ix in enumerate(indices):
    filename = img_data[ix]['new_filename']
    print(f"[{i+1}] {filename}")  # Console log

    # This code is for displaying on the plot the patient's original chest X-ray footage.
    plt.subplot(20, 3, i * 3 + 1)
    plt.imshow(np.squeeze(X_test_seg[ix]), cmap='gray')
    plt.title(f"Image: {filename}")
    plt.axis('off')

    # This code is for displaying the ground truth mask - the area in the chest X-ray where the doctor identified the Pneumothorax.
    plt.subplot(20, 3, i * 3 + 2)
    plt.imshow(np.squeeze(Y_test_seg[ix]), cmap='gray')
    plt.title("Ground Truth")
    plt.axis('off')

    # This code is for displaying the predicted segmentation area by the model.
    plt.subplot(20, 3, i * 3 + 3)
    plt.imshow(np.squeeze(pred_test_threshold[ix]), cmap='gray')
    plt.title("Prediction (Thresh > 0.6)")
    plt.axis('off')

plt.tight_layout()
plt.show()

indices = random.sample(range(len(X_test_seg)), 20)

# Step 4: Plot each sample with filename
plt.figure(figsize=(15, 60))  # Tall figure for 20 rows

for i, ix in enumerate(indices):
    filename = img_data[ix]['new_filename']
    print(f"[{i+1}] {filename}")  # Console log

    # Plot image
    plt.subplot(20, 3, i * 3 + 1)
    plt.imshow(np.squeeze(X_test_seg[ix]), cmap='gray')
    plt.title(f"Image: {filename}")
    plt.axis('off')

    # Plot ground truth mask
    plt.subplot(20, 3, i * 3 + 2)
    plt.imshow(np.squeeze(Y_test_seg[ix]), cmap='gray')
    plt.title("Ground Truth")
    plt.axis('off')

    # Plot predicted mask
    plt.subplot(20, 3, i * 3 + 3)
    plt.imshow(np.squeeze(pred_test_threshold[ix]), cmap='gray')
    plt.title("Prediction (Thresh > 0.6)")
    plt.axis('off')

plt.tight_layout()
plt.show()

pred_test = model.predict(X_test_seg, verbose=1)
pred_test_threshold = (pred_test > 0.35).astype(np.uint8)

# Step 2: Flatten both arrays
y_true = Y_test_seg.astype(np.uint8).flatten()
y_pred = pred_test_threshold.flatten()

# Step 3: Compute Intersection and Union
intersection = np.logical_and(y_true, y_pred).sum()
union = np.logical_or(y_true, y_pred).sum()

# Step 4: Calculate IoU
iou = intersection / union if union != 0 else 1.0

# Step 5: Calculate Dice
dice = (2. * intersection) / (y_true.sum() + y_pred.sum()) if (y_true.sum() + y_pred.sum()) != 0 else 1.0

# Step 6: Output
print(f"\n📊 Test Set Metrics:")
print(f"IoU Score:  {iou:.4f}")
print(f"Dice Score: {dice:.4f}")

# After predicting and thresholding
y_true = Y_test_seg.astype(np.uint8).flatten()
y_pred = pred_test_threshold.flatten()

# Compute accuracy
accuracy = np.mean(y_true == y_pred)

print(f"Segmentation Accuracy: {accuracy:.4f}")

def get_lung_side(mask):
    """Returns which lung(s) have pneumothorax in a given mask"""
    h, w = mask.shape
    left = mask[:, :w//2].sum() > 0
    right = mask[:, w//2:].sum() > 0
    if left and right:
        return "both"
    elif left:
        return "left"
    elif right:
        return "right"
    else:
        return "none"

# Prepare masks (remove channel dim if needed)
gt_masks = np.squeeze(Y_test_seg).astype(np.uint8)         # Shape: (N, H, W)
pred_masks = np.squeeze(pred_test_threshold).astype(np.uint8)  # Shape: (N, H, W)

# Compute per-sample lung side match
correct = 0
total = len(gt_masks)

for i in range(total):
    gt_side = get_lung_side(gt_masks[i])
    pred_side = get_lung_side(pred_masks[i])
    if gt_side == pred_side:
        correct += 1

# Compute percentage
percentage = (correct / total) * 100
print(f"🫁 Lung-side localization accuracy: {percentage:.2f}%")

def get_quadrant_map(mask):
    """Returns a set of quadrant names where the mask is positive"""
    h, w = mask.shape
    h2, w2 = h // 2, w // 2

    quad_map = set()
    if mask[0:h2, 0:w2].sum() > 0:
        quad_map.add('top-left')
    if mask[0:h2, w2:].sum() > 0:
        quad_map.add('top-right')
    if mask[h2:, 0:w2].sum() > 0:
        quad_map.add('bottom-left')
    if mask[h2:, w2:].sum() > 0:
        quad_map.add('bottom-right')
    return quad_map

# Prepare masks
gt_masks = np.squeeze(Y_test_seg).astype(np.uint8)         # (N, H, W)
pred_masks = np.squeeze(pred_test_threshold).astype(np.uint8)  # (N, H, W)

# Evaluate quadrant match
correct = 0
total = len(gt_masks)

for i in range(total):
    gt_quads = get_quadrant_map(gt_masks[i])
    pred_quads = get_quadrant_map(pred_masks[i])
    if gt_quads == pred_quads:
        correct += 1

# Result
percentage = (correct / total) * 100
print(f"📊 Quadrant-level localization accuracy: {percentage:.2f}%")